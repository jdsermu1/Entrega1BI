{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "young-production",
   "metadata": {},
   "source": [
    "# Busqueda de hiperparametros optimos\n",
    "Este cuaderno tiene la labor de encontrar la configuracion de hiperparametros optima. Se implementaron estrategias de podado del arbol de decision, sobremuestreo entre otros y validacion cruzada. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-drunk",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from progressbar import ProgressBar\n",
    "import random\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-decimal",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "En este cuaderno solo fue necesario cargar el conjunto de datos de entreno ya que por la estrategia de validacion cruzada se iba a dividir nuevamente este conjunto para verificar que no se estuviera incurriendo en sobreajuste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thirty-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-float",
   "metadata": {},
   "source": [
    "# Validacion cruzada y busqueda de hiperparametros\n",
    "Para hallar la configuracion optima del modelo de entrenamiento se establecio la lista de hiperparametros. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-relaxation",
   "metadata": {},
   "source": [
    "| Hiperparametro | Descripcion |\n",
    "| --- | --- |\n",
    "| binary | Elegir si al tokenizar los documentos hacerlo de forma binaria o contando las veces que se repitiera una palabra |\n",
    "| tfidf | En caso de que no se usara una estrategia binaria se tenia que decidir si usar la estrategia de pesado tfidf |\n",
    "|oversample|Se tenia que decidir si sobre muestrear la clase minoritaria|\n",
    "|SMOTE| Se tenia que decidir cual estrategia de sobre muestro realizar si SMOTE o sobre muestrao por bagging con repeticion|\n",
    "| criterio | el criterio de selecion de variables del arbol podia tomar valores de gini o entropy|\n",
    "|max_deph | estrategia de podado para evitar crecimiento excesivo del arbol y de esta forma evitar sobre ajuste del modelo se tomaron valores entre 40 y 200|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "floating-renewal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1000 of 1000) |####################| Elapsed Time: 0:25:06 Time:  0:25:06\n"
     ]
    }
   ],
   "source": [
    "bar = ProgressBar()\n",
    "def iterate(train, n = 1000, max_depth_range= (40, 201), n_splits=8):\n",
    "    best_run = None\n",
    "    best_average_f1_score = 0\n",
    "    for i in bar(range(n)):\n",
    "        run = {}\n",
    "        \n",
    "        run[\"binary\"] = random.randint(0,1)\n",
    "        run[\"tfidf\"] = random.randint(0,1) if not run[\"binary\"] else 0\n",
    "        run[\"oversample\"] = random.randint(0,1)\n",
    "        run[\"SMOTE\"] = random.randint(0,1) if run[\"oversample\"] else 0\n",
    "        run['criterion'] = \"gini\" if random.randint(0,1) else \"entropy\"\n",
    "        run[\"max_depth\"] = random.randrange(max_depth_range[0],max_depth_range[1])\n",
    "        sum_f1_1 = 0\n",
    "            \n",
    "        kf = KFold(n_splits=n_splits)\n",
    "        kf.get_n_splits(train)\n",
    "        for train_index, validation_index in kf.split(train):\n",
    "            y_train = None \n",
    "            training_data = train.iloc[train_index]\n",
    "            validation_data = train.iloc[validation_index]\n",
    "            \n",
    "            vect = CountVectorizer(binary=run[\"binary\"])\n",
    "            vect.fit(training_data[\"text\"])\n",
    "            train_encoded = vect.transform(training_data[\"text\"])\n",
    "            validation_encoded = vect.transform(validation_data[\"text\"])\n",
    "            \n",
    "            if run[\"tfidf\"]:\n",
    "                tfidf_transformer = TfidfTransformer()\n",
    "                tfidf_transformer.fit(train_encoded)\n",
    "                train_encoded = tfidf_transformer.transform(train_encoded)\n",
    "                validation_encoded = tfidf_transformer.transform(validation_encoded)\n",
    "\n",
    "                \n",
    "            if run['oversample']:\n",
    "                if run[\"SMOTE\"]:\n",
    "                    ros = SMOTE()\n",
    "                else:\n",
    "                    ros = RandomOverSampler()\n",
    "                train_encoded, y_train= ros.fit_resample(train_encoded, training_data[\"spam\"])\n",
    "        \n",
    "            clf = DecisionTreeClassifier(criterion=run['criterion'], \n",
    "                                         max_depth=run['max_depth'],\n",
    "                                         min_samples_split=2)\n",
    "        \n",
    "            if y_train is None:\n",
    "                y_train = training_data[\"spam\"]\n",
    "            \n",
    "            clf.fit(train_encoded, y_train)\n",
    "            sum_f1_1 += classification_report(validation_data[\"spam\"], \n",
    "                                                clf.predict(validation_encoded), output_dict=True)[\"1\"][\"f1-score\"]\n",
    "        run[\"average_f1_score\"] = sum_f1_1/n_splits\n",
    "        \n",
    "        if best_average_f1_score<run[\"average_f1_score\"]:\n",
    "            best_run = run\n",
    "            best_average_f1_score = run[\"average_f1_score\"]\n",
    "    return best_run\n",
    "        \n",
    "best = iterate(df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-integration",
   "metadata": {},
   "source": [
    "Para hallar los hiperparametros adecuados se realizo una busqueda aleatoria en vez de una busqueda en grilla y se itero por 1000 repeticiones, esto tomaba cerca de 20 minutos. Para elegir la configuracion optima se tomo como funcion objetivo el F1-Score. El F1-Score se eligio por las siguientes razones, en el negocio de la mensajeria de texto y multimedia ciertmente es costoso no etiquetar un mensaje fraudulento como fraudulento sin embargo tambien es costoso etiquetar un mensaje como fraudulento sin serlo. Dado que el F1-Score es el promedio entre el sensibilidad y la precision busca balancear estos dos requerimientos de forma que ambos se vean beneficiados. A continuacion se muestra la configuracion optima. Es importante resaltar que la funcion objetivo fue calculada unicamente para lso conjunto de validacion de cada iteracion de validacion cruzada, esto porque el F1-Score para los conjuntos de entreno no es una medida aplicable al mundo real para el modelo ya que se estaria calculando sobre los mismos datos que se entreno. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "million-residence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary': 1,\n",
       " 'tfidf': 0,\n",
       " 'oversample': 0,\n",
       " 'SMOTE': 0,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 196,\n",
       " 'average_f1_score': 0.8698598187266303}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
