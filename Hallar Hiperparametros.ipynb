{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Búsqueda de hiperparámetros óptimos\n",
    "Este cuaderno tiene la labor de encontrar la configuración de hiperparámetros óptima. Se implementaron estrategias de podado del árbol de decisión, sobremuestreo, entre otros, y finalmente validación cruzada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from progressbar import ProgressBar\n",
    "import random\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "En este cuaderno solo fue necesario cargar el conjunto de datos de entreno ya que por la estrategia de validación cruzada se iba a dividir nuevamente este conjunto para verificar que no se estuviera incurriendo en sobreajuste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación cruzada y búsqueda de hiperparámetros\n",
    "Para hallar la configuración óptima del modelo de entrenamiento se estableció la lista de hiperparámetros. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Hiperparámetro | Descripción |\n",
    "| --- | --- |\n",
    "| binary | Elegir si al tokenizar los documentos hacerlo de forma binaria o contando las veces que se repitiera una palabra |\n",
    "| tfidf | En caso de que no se usara una estrategia binaria se tenia que decidir si usar la estrategia de pesado tfidf |\n",
    "|oversample|Se tenia que decidir si sobre muestrear la clase minoritaria|\n",
    "|SMOTE| Se tenia que decidir cual estrategia de sobre muestro realizar si SMOTE o sobre muestrao por bagging con repeticion|\n",
    "| criterio | el criterio de selecion de variables del arbol podia tomar valores de gini o entropy|\n",
    "|max_deph | estrategia de podado para evitar crecimiento excesivo del arbol y de esta forma evitar sobre ajuste del modelo se tomaron valores entre 40 y 200|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1000 of 1000) |####################| Elapsed Time: 0:25:06 Time:  0:25:06\n"
     ]
    }
   ],
   "source": [
    "bar = ProgressBar()\n",
    "def iterate(train, n = 1000, max_depth_range= (40, 201), n_splits=8):\n",
    "    best_run = None\n",
    "    best_average_f1_score = 0\n",
    "    for i in bar(range(n)):\n",
    "        run = {}\n",
    "        \n",
    "        run[\"binary\"] = random.randint(0,1)\n",
    "        run[\"tfidf\"] = random.randint(0,1) if not run[\"binary\"] else 0\n",
    "        run[\"oversample\"] = random.randint(0,1)\n",
    "        run[\"SMOTE\"] = random.randint(0,1) if run[\"oversample\"] else 0\n",
    "        run['criterion'] = \"gini\" if random.randint(0,1) else \"entropy\"\n",
    "        run[\"max_depth\"] = random.randrange(max_depth_range[0],max_depth_range[1])\n",
    "        sum_f1_1 = 0\n",
    "            \n",
    "        kf = KFold(n_splits=n_splits)\n",
    "        kf.get_n_splits(train)\n",
    "        for train_index, validation_index in kf.split(train):\n",
    "            y_train = None \n",
    "            training_data = train.iloc[train_index]\n",
    "            validation_data = train.iloc[validation_index]\n",
    "            \n",
    "            vect = CountVectorizer(binary=run[\"binary\"])\n",
    "            vect.fit(training_data[\"text\"])\n",
    "            train_encoded = vect.transform(training_data[\"text\"])\n",
    "            validation_encoded = vect.transform(validation_data[\"text\"])\n",
    "            \n",
    "            if run[\"tfidf\"]:\n",
    "                tfidf_transformer = TfidfTransformer()\n",
    "                tfidf_transformer.fit(train_encoded)\n",
    "                train_encoded = tfidf_transformer.transform(train_encoded)\n",
    "                validation_encoded = tfidf_transformer.transform(validation_encoded)\n",
    "\n",
    "                \n",
    "            if run['oversample']:\n",
    "                if run[\"SMOTE\"]:\n",
    "                    ros = SMOTE()\n",
    "                else:\n",
    "                    ros = RandomOverSampler()\n",
    "                train_encoded, y_train= ros.fit_resample(train_encoded, training_data[\"spam\"])\n",
    "        \n",
    "            clf = DecisionTreeClassifier(criterion=run['criterion'], \n",
    "                                         max_depth=run['max_depth'],\n",
    "                                         min_samples_split=2)\n",
    "        \n",
    "            if y_train is None:\n",
    "                y_train = training_data[\"spam\"]\n",
    "            \n",
    "            clf.fit(train_encoded, y_train)\n",
    "            sum_f1_1 += classification_report(validation_data[\"spam\"], \n",
    "                                                clf.predict(validation_encoded), output_dict=True)[\"1\"][\"f1-score\"]\n",
    "        run[\"average_f1_score\"] = sum_f1_1/n_splits\n",
    "        \n",
    "        if best_average_f1_score<run[\"average_f1_score\"]:\n",
    "            best_run = run\n",
    "            best_average_f1_score = run[\"average_f1_score\"]\n",
    "    return best_run\n",
    "        \n",
    "best = iterate(df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hallar los hiperparametros adecuados se realizó una búsqueda aleatoria en vez de una búsqueda en grilla y se iteró por 1000 repeticiones, esto tomaba cerca de 20 minutos. Para elegir la configuracion óptima se tomó como función objetivo el F1-Score. El F1-Score se eligió por las siguientes razones, en el negocio de la mensajeria de texto y multimedia ciertmente es costoso no etiquetar un mensaje fraudulento como fraudulento, sin embargo, también es costoso etiquetar un mensaje como fraudulento sin serlo. Dado que el F1-Score es el promedio entre el sensibilidad y la precision busca balancear estos dos requerimientos de forma que ambos se vean beneficiados. Es importante resaltar que la función objetivo fue calculada únicamente para los conjuntos de validación de cada iteración de validación cruzada, esto porque el F1-Score para los conjuntos de entreno no es una medida aplicable al mundo real para el modelo ya que se estaría calculando sobre los mismos datos que se entreno. A continuación se muestra la configuración óptima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary': 1,\n",
       " 'tfidf': 0,\n",
       " 'oversample': 0,\n",
       " 'SMOTE': 0,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 196,\n",
       " 'average_f1_score': 0.8698598187266303}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
